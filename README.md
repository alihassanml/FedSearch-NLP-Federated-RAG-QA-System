# ğŸš€ FedSearch-NLP: Federated RAG QA System

A production-ready FastAPI backend for enterprise document search and question answering using Retrieval-Augmented Generation (RAG).

## ğŸ“‹ Features

âœ… **RAG Pipeline**: Combines document retrieval with LLM-based answer generation  
âœ… **FAISS Vector Search**: Fast semantic document search  
âœ… **Enterprise Ready**: Built with FastAPI for production use  
âœ… **Sample Data Included**: Pre-loaded with company documents  
âœ… **Interactive API Docs**: Auto-generated Swagger UI  
âœ… **Extensible**: Easy to add federated learning capabilities

---

## ğŸ—ï¸ Project Structure

```
fedsearch_nlp/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py           # API endpoints
â”‚   â”‚   â””â”€â”€ models.py           # Request/response models
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”‚   â””â”€â”€ rag_engine.py       # RAG orchestration
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ document_processor.py  # Document loading
â”‚       â”œâ”€â”€ retriever.py           # FAISS retrieval
â”‚       â””â”€â”€ generator.py           # Answer generation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ company_docs/           # ğŸ“„ Company documents (YOUR DATA)
â”‚   â”‚   â”œâ”€â”€ hr_policy.txt
â”‚   â”‚   â”œâ”€â”€ it_sop.txt
â”‚   â”‚   â”œâ”€â”€ legal_doc.txt
â”‚   â”‚   â””â”€â”€ product_guide.txt
â”‚   â””â”€â”€ embeddings/             # Generated FAISS indices
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## âš¡ Quick Start (3 Steps)

### Option 1: Automated Setup (Recommended)

```bash
# 1. Make setup script executable
chmod +x setup_and_run.sh

# 2. Run setup
./setup_and_run.sh

# 3. Start server
source venv/bin/activate
python -m uvicorn app.main:app --reload
```

### Option 2: Manual Setup

```bash
# 1. Create directories
mkdir -p app/api app/core app/services app/utils
mkdir -p data/company_docs data/embeddings models

# 2. Create __init__.py files
touch app/__init__.py app/api/__init__.py app/core/__init__.py
touch app/services/__init__.py app/utils/__init__.py

# 3. Install dependencies
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 4. Create company documents (see data creation script)
python create_company_docs.py

# 5. Start server
python -m uvicorn app.main:app --reload
```

---

## ğŸ¯ Usage

### 1. Access API Documentation

Open your browser: **http://localhost:8000/docs**

### 2. Index Documents (First Time)

```bash
curl -X POST "http://localhost:8000/api/index" \
  -H "Content-Type: application/json" \
  -d '{"reindex": false}'
```

**Response:**
```json
{
  "status": "success",
  "documents_indexed": 42,
  "message": "Index built successfully"
}
```

### 3. Query the System

```bash
curl -X POST "http://localhost:8000/api/query" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is the annual leave policy?",
    "top_k": 3
  }'
```

**Response:**
```json
{
  "answer": "The annual leave policy provides 20 days per year for full-time employees.",
  "retrieved_documents": [
    {
      "content": "Annual Leave: 20 days per year...",
      "score": 0.89,
      "source": "hr_policy.txt"
    }
  ],
  "confidence": 0.92
}
```

### 4. Check System Health

```bash
curl http://localhost:8000/api/health
```

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API overview |
| GET | `/api/health` | System health check |
| POST | `/api/index` | Index/reindex documents |
| POST | `/api/query` | Ask questions |
| GET | `/api/documents/stats` | Document statistics |

---

## ğŸ§ª Test Queries

Try these sample questions:

```bash
# HR Policy
"How many sick leave days do employees get?"
"What is the remote work policy?"
"When are salary reviews conducted?"

# IT Procedures
"What is the password policy?"
"How do I report a security incident?"
"How often are backups performed?"

# Legal
"What is the data retention policy?"
"How long is the non-compete clause?"

# Products
"What is the pricing for CloudSync Pro?"
"Which products support SSO?"
"What compliance certifications do we have?"
```

---

## ğŸ“„ Company Documents (Data Files)

The system includes 4 sample company documents in `data/company_docs/`:

1. **hr_policy.txt** - HR policies (leave, benefits, working hours)
2. **it_sop.txt** - IT procedures (access, backups, security)
3. **legal_doc.txt** - Legal guidelines (IP, compliance, contracts)
4. **product_guide.txt** - Product information (pricing, features)

### Adding Your Own Documents

1. Place `.txt` files in `data/company_docs/`
2. Reindex documents:
   ```bash
   curl -X POST "http://localhost:8000/api/index" \
     -H "Content-Type: application/json" \
     -d '{"reindex": true}'
   ```

---

## ğŸ”§ Configuration

Edit `.env` file to customize:

```env
# Models
RETRIEVER_MODEL="sentence-transformers/all-MiniLM-L6-v2"
GENERATOR_MODEL="google/flan-t5-base"

# Performance
TOP_K=3
MAX_LENGTH=512

# Paths
COMPANY_DOCS_PATH="data/company_docs"
EMBEDDINGS_PATH="data/embeddings"
```

---

## ğŸš€ Production Deployment

### Docker (Coming Soon)

```bash
docker build -t fedsearch-nlp .
docker run -p 8000:8000 fedsearch-nlp
```

### Systemd Service

```bash
# Create service file
sudo nano /etc/systemd/system/fedsearch.service

# Add configuration (see docs)
sudo systemctl enable fedsearch
sudo systemctl start fedsearch
```

---

## ğŸ§  How It Works

1. **Document Processing**: Text files are split into semantic chunks
2. **Embedding**: Each chunk is converted to a 384-dim vector
3. **Indexing**: FAISS creates a searchable vector database
4. **Retrieval**: User query â†’ vector â†’ find top-K similar chunks
5. **Generation**: Flan-T5 generates answer from retrieved context

---

## ğŸ› ï¸ Tech Stack

- **FastAPI** - Web framework
- **Sentence-Transformers** - Document embeddings
- **FAISS** - Vector similarity search
- **Transformers** - Flan-T5 for answer generation
- **PyTorch** - Deep learning backend

---

## ğŸ“Š Performance

- **Indexing**: ~50 documents/second
- **Query Latency**: ~500ms (CPU), ~200ms (GPU)
- **Memory**: ~2GB (models + indices)

---

## ğŸ”® Future Enhancements

- [ ] Federated Learning integration
- [ ] Multi-client architecture
- [ ] Differential privacy (DP-SGD)
- [ ] PDF/DOCX support
- [ ] User authentication
- [ ] Chat history
- [ ] Streaming responses

---

## ğŸ› Troubleshooting

### Models not downloading?

Set cache directory:
```bash
export TRANSFORMERS_CACHE="./models"
export SENTENCE_TRANSFORMERS_HOME="./models"
```

### Out of memory?

Use smaller models in `.env`:
```env
RETRIEVER_MODEL="sentence-transformers/all-MiniLM-L6-v2"
GENERATOR_MODEL="google/flan-t5-small"
```

### Port already in use?

Change port in `.env`:
```env
PORT=8001
```

---

## ğŸ“ License

MIT License - See LICENSE file

---

## ğŸ¤ Contributing

Pull requests welcome! For major changes, please open an issue first.

---

## ğŸ“ Support

- ğŸ“§ Email: support@example.com
- ğŸ› Issues: GitHub Issues
- ğŸ“š Docs: http://localhost:8000/docs

---

**Built with â¤ï¸ for enterprise document search**